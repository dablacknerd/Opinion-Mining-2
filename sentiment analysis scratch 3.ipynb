{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tomOpinionMining1 import *\n",
    "\n",
    "def polarity_mapper(score):\n",
    "    if score < 0.0:\n",
    "        return '-1'\n",
    "    elif score > 0.0:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def polarity_mapper_1(score):\n",
    "    if str(score) == '1':\n",
    "        return '1'\n",
    "    elif str(score) == '0':\n",
    "        return '-1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\aoguntuga\\\\Documents\\\\Datasets\\\\Sentiment Analysis\\\\sentiment labelled sentences\\\\imdb_labelled.txt\"\n",
    "sent_frame = pd.read_csv(file_path,sep='\\t',header=None)\n",
    "sent_frame.columns =['Sentence','Dataset Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = list(sent_frame.index.values)\n",
    "my_polarity_list =[]\n",
    "my_subjectivity_list =[]\n",
    "\n",
    "for k in link:\n",
    "    tex = sent_frame['Sentence'][k].rstrip().decode('utf-8')\n",
    "    #print tex\n",
    "    #print k\n",
    "    score = sentiment_analysis(tex)\n",
    "    my_polarity_list.append(score[0])\n",
    "    my_subjectivity_list.append(score[1])\n",
    "\n",
    "sent_frame['My Polarity Score'] = my_polarity_list\n",
    "sent_frame['Subjectivity'] = my_subjectivity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapped_pol_1 =[polarity_mapper(x) for x in sent_frame['My Polarity Score']]\n",
    "sent_frame['My Polarity Score Conv'] = mapped_pol_1\n",
    "sent_frame['Dataset Polarity Score Conv'] = [polarity_mapper_1(k) for k in sent_frame['Dataset Polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Dataset Polarity</th>\n",
       "      <th>My Polarity Score</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>My Polarity Score Conv</th>\n",
       "      <th>Dataset Polarity Score Conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Dataset Polarity  \\\n",
       "0  A very, very, very slow-moving, aimless movie ...                 0   \n",
       "1  Not sure who was more lost - the flat characte...                 0   \n",
       "2  Attempting artiness with black & white and cle...                 0   \n",
       "3       Very little music or anything to speak of.                   0   \n",
       "\n",
       "   My Polarity Score  Subjectivity My Polarity Score Conv  \\\n",
       "0               0.00           0.8                      0   \n",
       "1              -0.09           0.8                     -1   \n",
       "2              -0.03           0.9                     -1   \n",
       "3              -0.03           0.8                     -1   \n",
       "\n",
       "  Dataset Polarity Score Conv  \n",
       "0                          -1  \n",
       "1                          -1  \n",
       "2                          -1  \n",
       "3                          -1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_frame.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 412.0\n",
      "Percentage match: 55.0802139037 percent\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "vin = []\n",
    "for i in link:\n",
    "    if sent_frame['My Polarity Score Conv'][i] == sent_frame['Dataset Polarity Score Conv'][i]:\n",
    "        vin.append(1)\n",
    "    else:\n",
    "        vin.append(0)\n",
    "sent_frame['Polarity Score'] = vin\n",
    "x = float(sent_frame['Polarity Score'].sum())\n",
    "total = len(link)\n",
    "print \"Number of matches: %s\" % x\n",
    "\n",
    "x_percent = x/total * 100.0\n",
    "\n",
    "print \"Percentage match: %s percent\" % x_percent\n",
    "out_file =\"C:\\\\Users\\\\aoguntuga\\\\Documents\\\\Sentiment Analysis Research\\\\Results\\\\sw_test_2.xlsx\"\n",
    "sent_frame.to_excel(out_file)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tomOpinionMining1 import *\n",
    "\n",
    "text ='A very, very, very slow-moving, aimless movie about a distressed, drifting young man.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_after_postag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-1ce68d9c4a64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlemma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtext_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtext_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_after_postag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtext_pos_norm\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnew_text_list\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_after_postag' is not defined"
     ]
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "text_token = word_tokenize(text)\n",
    "text_pos = preprocess_after_postag(pos_tag(text_token))\n",
    "text_pos_norm =[]\n",
    "new_text_list =[]\n",
    "for t in text_pos:\n",
    "    lem = lemma.lemmatize(t[0])\n",
    "    print lem\n",
    "    text_pos_norm.append((lem,t[1]))\n",
    "    new_text_list.append(lem)\n",
    "new_text = ' '.join(new_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A very , very , very slow moving , aimless movie about a distressed , drifting young man .\n",
      "[('A', 'DT'), ('very', 'RB'), (',', ','), ('very', 'RB'), (',', ','), ('very', 'RB'), ('slow', 'JJ'), ('moving', 'NN'), (',', ','), ('aimless', 'JJ'), ('movie', 'NN'), ('about', 'IN'), ('a', 'DT'), ('distressed', 'JJ'), (',', ','), ('drifting', 'VBG'), ('young', 'JJ'), ('man', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print new_text\n",
    "print text_pos_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn = create_syn_set_annotation(text_pos_norm,new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('very.r.02'),\n",
       " Synset('very.r.02'),\n",
       " Synset('very.r.02'),\n",
       " Synset('slow.a.04'),\n",
       " Synset('movie.n.01'),\n",
       " Synset('dysphoric.a.01'),\n",
       " Synset('stray.v.02'),\n",
       " Synset('young.a.01'),\n",
       " Synset('valet.n.01')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very.r.02:0.25\n",
      "very.r.02:0.25\n",
      "very.r.02:0.25\n",
      "slow.a.04:0.0\n",
      "movie.n.01:0.0\n",
      "dysphoric.a.01:-0.75\n",
      "stray.v.02:0.0\n",
      "young.a.01:0.0\n",
      "valet.n.01:0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limp = []\n",
    "for s in syn:\n",
    "    pos_score = swn.senti_synset(s.name()).pos_score()\n",
    "    neg_score = swn.senti_synset(s.name()).neg_score()\n",
    "    polarity_score = pos_score - neg_score\n",
    "    print \"%s:%s\" % (s.name(),polarity_score)\n",
    "    limp.append(polarity_score)\n",
    "round(np.mean(np.array(limp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print lesk(text,'slowmoving','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "if re.match(r'[a-zA-Z]*-[a-zA-Z]*','slow+moving'):\n",
    "    print 'yes'\n",
    "else:\n",
    "    print 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slow', 'moving']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'slow-moving'.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text_tokens):\n",
    "    return_list =[]\n",
    "    for t in text_tokens:\n",
    "        if re.match(r'[a-zA-Z]*-[a-zA-Z]*',t):\n",
    "            t_list = t.split('-')\n",
    "            for t_i in t_list:\n",
    "                return_list.append(t_i)\n",
    "        else:\n",
    "            return_list.append(t)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'very',\n",
       " ',',\n",
       " 'very',\n",
       " ',',\n",
       " 'very',\n",
       " 'slow',\n",
       " 'moving',\n",
       " ',',\n",
       " 'aimless',\n",
       " 'movie',\n",
       " 'about',\n",
       " 'a',\n",
       " 'distressed',\n",
       " ',',\n",
       " 'drifting',\n",
       " 'young',\n",
       " 'man',\n",
       " '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-b3e665da8c1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mswn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msenti_synset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'moving'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\aoguntuga\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\nltk\\corpus\\reader\\sentiwordnet.pyc\u001b[0m in \u001b[0;36msenti_synset\u001b[1;34m(self, *vals)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSentiSynset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0msynset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msynset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m's'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\aoguntuga\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.pyc\u001b[0m in \u001b[0;36msynset\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msynset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;31m# split name into lemma, part of speech and synset number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m         \u001b[0mlemma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynset_index_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m         \u001b[0msynset_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynset_index_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "swn.senti_synset('moving').pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('slow-moving.s.01')\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "s = wn.synsets('slow-moving')[0]\n",
    "print s\n",
    "print swn.senti_synset(s.name()).pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text2 = 'A very, very, very slow-moving, aimless movie about a distressed, drifting young man.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_pos = pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('very', 'RB'), (',', ','), ('very', 'RB'), (',', ','), ('very', 'RB'), ('slow', 'JJ'), ('moving', 'JJ'), (',', ','), ('aimless', 'JJ'), ('movie', 'NN'), ('about', 'IN'), ('a', 'DT'), ('distressed', 'JJ'), (',', ','), ('drifting', 'VBG'), ('young', 'JJ'), ('man', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "new_text_pos =[]\n",
    "for tp in text_pos:\n",
    "    if re.match(r'[a-zA-Z]*-[a-zA-Z]*',tp[0]):\n",
    "        tp_lisp = tp[0].split('-')\n",
    "        for tiny in tp_lisp:\n",
    "            new_text_pos.append((tiny,tp[1]))\n",
    "    else:\n",
    "        new_text_pos.append(tp)\n",
    "print new_text_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
